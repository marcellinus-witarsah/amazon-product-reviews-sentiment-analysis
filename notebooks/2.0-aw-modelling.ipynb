{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Insert project folder into Python System\n",
    "load_dotenv(find_dotenv())\n",
    "sys.path.append(os.getenv(\"PROJECT_FOLDER\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer + MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logger_name: str) -> None:\n",
    "        log_fmt = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "        self.logger_name = logger_name\n",
    "\n",
    "    def get_logger(self) -> logging.Logger:\n",
    "        self.logger = logging.getLogger(self.logger_name)\n",
    "        return self.logger\n",
    "\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "sys.path.append(os.getenv(\"PROJECT_FOLDER\"))\n",
    "from src.logger import Logger\n",
    "\n",
    "\n",
    "class DataSplitting:\n",
    "    def __init__(self, df: pd.DataFrame, test_size: float = 0.3):\n",
    "        \"\"\"Initialize `DataSplitting` class\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): dataset\n",
    "            test_size (float): test size proportion\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.test_size = test_size\n",
    "        self.logger = Logger(__name__).get_logger()\n",
    "\n",
    "    def train_val_test_split(self) -> Union[Tuple[pd.DataFrame], Tuple[pd.Series]]:\n",
    "        \"\"\"Split data into train, validation and test\n",
    "\n",
    "        Returns:\n",
    "            Union[Tuple[pd.DataFrame], Tuple[pd.Series]]: splitted dataset\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Splitting Data ...\")\n",
    "        X, y = (\n",
    "            self.df.loc[:, ~self.df.columns.isin([\"sentiment\"])],\n",
    "            self.df[[\"sentiment\"]],\n",
    "        )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, stratify=y, test_size=self.test_size, shuffle=True, random_state=42\n",
    "        )  # split main data into training and test\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_test,\n",
    "            y_test,\n",
    "            stratify=y_test,\n",
    "            test_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=42,\n",
    "        )  # split test data into validation and test\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 16:56:36,981 - __main__ - INFO - Splitting Data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_precision_score': 0.8267810551452704, 'training_recall_score': 0.9096482265362721, 'training_f1_score': 0.866237316406431, 'validation_precision_score': 0.7695234281137365, 'validation_recall_score': 0.8724177071509648, 'validation_f1_score': 0.8177465687839132, 'test_precision_score': 0.7806267806267806, 'test_recall_score': 0.8710263396911898, 'test_f1_score': 0.8233526507834299}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" MODEL TRAINING \"\"\"\n",
    "# mlflow.set_tracking_uri(\"./mlruns\")  # Set tracking server (aka file)\n",
    "# mlflow.set_experiment(\"Sentiment Classification\")  # Set experiment\n",
    "# run_name = \"countvec-multinomialnb-run\"  # set run name\n",
    "# artifact_path = \"countvec-multinomialnb\"  # set artifact path\n",
    "\n",
    "# load Data\n",
    "df = pd.read_csv(\"../data/processed/sample-clean-data.csv\")\n",
    "\n",
    "# Split Data\n",
    "# X, y = df.loc[:, ~df.columns.isin(['sentiment'])], df[['sentiment']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, shuffle=True, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, stratify=y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = DataSplitting(df, 0.3).train_val_test_split()\n",
    "\n",
    "# Modelling\n",
    "params = {}  # means using default params\n",
    "model = Pipeline([\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('MultinomialNB', MultinomialNB(**params))\n",
    "])\n",
    "model.fit(X_train['preprocessed_review_text'], y_train['sentiment'])\n",
    "# signature = mlflow.models.infer_signature(X_train[['preprocessed_review_text']], y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "metrics = {\n",
    "    \"training_precision_score\": precision_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"training_recall_score\": recall_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"training_f1_score\": f1_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"validation_precision_score\": precision_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"validation_recall_score\": recall_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"validation_f1_score\": f1_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"test_precision_score\": precision_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text'])),\n",
    "    \"test_recall_score\": recall_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text'])),\n",
    "    \"test_f1_score\": f1_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text']))\n",
    "}\n",
    "print(metrics)\n",
    "\n",
    "# with mlflow.start_run(run_name=run_name):\n",
    "#     # log hyperparameters\n",
    "#     mlflow.log_params(params)\n",
    "\n",
    "#     # log metrics\n",
    "#     mlflow.log_metrics(metrics)\n",
    "    \n",
    "#     # Log model\n",
    "#     mlflow.sklearn.log_model(\n",
    "#         sk_model=model,\n",
    "#         artifact_path=artifact_path,\n",
    "#         signature=signature\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19627</th>\n",
       "      <td>red blue stamp fine green like lime true green...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>realize buy 200 dollar programming tool make w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11857</th>\n",
       "      <td>maddening ford deal reese pre-install reese ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29952</th>\n",
       "      <td>light small work fine although speaker small w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47042</th>\n",
       "      <td>good quality long lead happy purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13217</th>\n",
       "      <td>1st one received wrong car putting aside quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17016</th>\n",
       "      <td>original receiver came order stopped working m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44025</th>\n",
       "      <td>pretty sturdy stencil nice image look forward ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12723</th>\n",
       "      <td>light weight compact picture show round disc f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40678</th>\n",
       "      <td>love ty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33667 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocessed_review_text\n",
       "19627  red blue stamp fine green like lime true green...\n",
       "15287  realize buy 200 dollar programming tool make w...\n",
       "11857  maddening ford deal reese pre-install reese ba...\n",
       "29952  light small work fine although speaker small w...\n",
       "47042              good quality long lead happy purchase\n",
       "...                                                  ...\n",
       "13217  1st one received wrong car putting aside quali...\n",
       "17016  original receiver came order stopped working m...\n",
       "44025  pretty sturdy stencil nice image look forward ...\n",
       "12723  light weight compact picture show round disc f...\n",
       "40678                                            love ty\n",
       "\n",
       "[33667 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer + MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\923006079\\AppData\\Local\\anaconda3\\envs\\nlp-tools\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\923006079\\AppData\\Local\\anaconda3\\envs\\nlp-tools\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\923006079\\AppData\\Local\\anaconda3\\envs\\nlp-tools\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\" MODEL TRAINING \"\"\"\n",
    "mlflow.set_tracking_uri(\"./mlruns\")  # Set tracking server (aka file)\n",
    "mlflow.set_experiment(\"Sentiment Classification\")  # Set experiment\n",
    "run_name = \"tfidf-multinomialnb-run\"  # set run name\n",
    "artifact_path = \"tfidf-multinomialnb\"  # set artifact path\n",
    "\n",
    "# load Data\n",
    "df = pd.read_csv(\"../data/processed/sample-clean-data.csv\")\n",
    "\n",
    "# Split Data\n",
    "df['sentiment'] = df['sentiment'].map({\"positive\": 1, \"negative\": 0}) \n",
    "X, y = df.loc[:, ~df.columns.isin(['sentiment'])], df[['sentiment']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, stratify=y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelling\n",
    "params = {}  # means using default params\n",
    "model = Pipeline([\n",
    "    ('TfidfVectorizer', TfidfVectorizer()),\n",
    "    ('MultinomialNB', MultinomialNB(**params))\n",
    "])\n",
    "model.fit(X_train['preprocessed_review_text'], y_train['sentiment'])\n",
    "signature = mlflow.models.infer_signature(X_train[['preprocessed_review_text']], y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "metrics = {\n",
    "    \"training_precision_score\": precision_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"training_recall_score\": recall_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"training_f1_score\": f1_score(y_train['sentiment'], model.predict(X_train['preprocessed_review_text'])),\n",
    "    \"validation_precision_score\": precision_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"validation_recall_score\": recall_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"validation_f1_score\": f1_score(y_val['sentiment'], model.predict(X_val['preprocessed_review_text'])),\n",
    "    \"test_precision_score\": precision_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text'])),\n",
    "    \"test_recall_score\": recall_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text'])),\n",
    "    \"test_f1_score\": f1_score(y_test['sentiment'], model.predict(X_test['preprocessed_review_text']))\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # log hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # log metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        signature=signature\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
